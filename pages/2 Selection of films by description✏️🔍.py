import streamlit as st
import pandas as pd
import torch
from transformers import BertTokenizer, BertModel
import faiss
import numpy as np
import re
import nltk
from nltk.corpus import stopwords

# –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–æ–ø-—Å–ª–æ–≤ –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

@st.cache_data
def load_data(url):
    df = pd.read_csv(url)
    return df

@st.cache_data
def embedding_and_index():
    embeddings_array = np.load('data/embeddings_eng.npy')
    index = faiss.read_index('data/desc_faiss_index_eng.index')
    return embeddings_array, index

@st.cache_data
def load_model():
    model = BertModel.from_pretrained('bert-base-uncased')
    return model

def clean_text(text):
    text = text.lower()
    text = re.sub(r'[^\w\s]', '', text)
    text = ' '.join(word for word in text.split() if word not in stop_words)
    
    return text

st.header("Selection of films by description‚úèÔ∏èüîç")

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
df = load_data('data/eng_data.csv')
embeddings_array, index = embedding_and_index()
model = load_model()

# –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –≤–≤–æ–¥
user_input = st.text_input("Enter a movie description:", value="", help="The more detailed your description is, the more accurately we can choose a film for you ü§ó'")

if st.button("Searchüîçüé¶"):
    if user_input:
        def encode_description(description, tokenizer, model):
            tokens = tokenizer(description, return_tensors="pt")
            with torch.no_grad():
                outputs = model(**tokens)
            embeddings = outputs.last_hidden_state.mean(dim=1)
            return embeddings.cpu().numpy().astype('float32')
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –æ—á–∏—Å—Ç–∫—É —Ç–µ–∫—Å—Ç–∞ –∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–º—É –≤–≤–æ–¥—É
        cleaned_input = clean_text(user_input)
        
        # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –æ—á–∏—â–µ–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        input_embedding = encode_description(cleaned_input, tokenizer, model)

        # –ü–æ–∏—Å–∫ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Faiss
        _, sorted_indices = index.search(input_embedding.reshape(1, -1), 5)

        # –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—Ç—Ä–æ–∫ –∏–∑ DataFrame
        recs = df.iloc[sorted_indices[0]].reset_index(drop=True)
        recs.index = recs.index + 1

        # –í—ã–≤–æ–¥ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∏–ª—å–º–æ–≤ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
        st.subheader("Recommended movies üéâ:")
        for i in range(5):
            st.markdown(f"<span style='font-size:{20}px; color:purple'>{recs['movie_title'].iloc[i]}</span>", unsafe_allow_html=True)
        # –°–æ–∑–¥–∞–µ–º –¥–≤–µ –∫–æ–ª–æ–Ω–∫–∏: –æ–¥–Ω—É –¥–ª—è —Ç–µ–∫—Å—Ç–∞, –¥—Ä—É–≥—É—é –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            col1, col2 = st.columns([2, 1])
    
        # –í  –∫–æ–ª–æ–Ω–∫–µ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Ñ–∏–ª—å–º–∞, –æ–ø–∏—Å–∞–Ω–∏–µ, —Ä–æ–ª–∏ –∏ —Å—Å—ã–ª–∫—É
            col1.info(recs['description'].iloc[i])
            col1.markdown(f"**You can watch the film [here]({recs['page_url'].iloc[i]})**")
    
        # –í  –∫–æ–ª–æ–Ω–∫–µ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            col2.image(recs['image_url'].iloc[i], caption=recs['movie_title'].iloc[i], width=200)
        with st.sidebar:
            st.info("""
                 #### Were we able to help you with the choice? 
                """)
            feedback = st.text_input('Share with us')
        
            feedback_button = st.button("Send feedback", key="feedback_button")
        
        if feedback_button and feedback:
            feedback_container.success("Thank you, every day we try to be better for you üíü")
        elif feedback_button:
            feedback_container.warning("Please enter a review before submitting")