import streamlit as st
import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModel
import faiss
import numpy as np

@st.cache_data
def load_data(url):
    df = pd.read_csv(url)
    return df

@st.cache_data
def embedding_and_index():
    embeddings_array = np.load('data/embeddings_final.npy')
    index = faiss.read_index('data/desc_faiss_index_final.index')
    return embeddings_array, index

@st.cache_data
def load_model():
    model = AutoModel.from_pretrained("DeepPavlov/rubert-base-cased-sentence")
    return model


st.header("–ü–æ–¥–±–æ—Ä —Ñ–∏–ª—å–º–æ–≤ –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é ‚úèÔ∏èüîç")

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
tokenizer = AutoTokenizer.from_pretrained("DeepPavlov/rubert-base-cased-sentence")
df = load_data('data/final_data.csv')
embeddings_array, index = embedding_and_index()
model = load_model()

# –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –≤–≤–æ–¥
user_input = st.text_input("–í–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ñ–∏–ª—å–º–∞:", value="", help="–ß–µ–º –ø–æ–¥—Ä–æ–±–Ω–µ–µ –±—É–¥–µ—Ç –≤–∞—à–µ –æ–ø–∏—Å–∞–Ω–∏–µ, —Ç–µ–º —Ç–æ—á–Ω–µ–µ –º—ã —Å–º–æ–∂–µ–º –ø–æ–¥–æ–±—Ä–∞—Ç—å –¥–ª—è –≤–∞—Å —Ñ–∏–ª—å–º ü§ó'")
genre_list = ['–∞–Ω–∏–º–∞—Ü–∏—è', '–∞–Ω–∏–º–µ', '–±–∞–ª–µ—Ç', '–±–∏–æ–≥—Ä–∞—Ñ–∏—è', '–±–æ–µ–≤–∏–∫', '–≤–µ—Å—Ç–µ—Ä–Ω', '–≤–æ–µ–Ω–Ω—ã–π', '–¥–µ—Ç–µ–∫—Ç–∏–≤', '–¥–µ—Ç—Å–∫–∏–π', '–¥–æ–∫—É–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π', '–¥—Ä–∞–º–∞', '–∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π', '–∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ–∞', '–∫–æ–º–µ–¥–∏—è', '–∫–æ–Ω—Ü–µ—Ä—Ç', '–∫–æ—Ä–æ—Ç–∫–æ–º–µ—Ç—Ä–∞–∂–Ω—ã–π', '–∫—Ä–∏–º–∏–Ω–∞–ª', '–º–µ–ª–æ–¥—Ä–∞–º–∞', '–º–∏—Å—Ç–∏–∫–∞', '–º—É–∑—ã–∫–∞', '–º—é–∑–∏–∫–ª', '–Ω—É–∞—Ä', '–ø—Ä–∏–∫–ª—é—á–µ–Ω–∏—è', '—Å–±–æ—Ä–Ω–∏–∫', '—Å–µ–º–µ–π–Ω—ã–π', '—Å–∫–∞–∑–∫–∞', '—Å–ø–æ—Ä—Ç', '—Ç—Ä–∏–ª–ª–µ—Ä', '—É–∂–∞—Å—ã', '—Ñ–∞–Ω—Ç–∞—Å—Ç–∏–∫–∞', '—Ñ—ç–Ω—Ç–µ–∑–∏', '—ç—Ä–æ—Ç–∏–∫–∞']

user_select_genre = st.multiselect('–í—ã–±–µ—Ä–∏—Ç–µ –∂–∞–Ω—Ä', genre_list)

if st.button("–ò—Å–∫–∞—Ç—åüîçüé¶"):
    if user_input:
        def encode_description(description, tokenizer, model):
            tokens = tokenizer(description, return_tensors="pt")
            with torch.no_grad():
                outputs = model(**tokens)
            embeddings = outputs.last_hidden_state.mean(dim=1)
            return embeddings.cpu().numpy().astype('float32')

        # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –≤–≤–µ–¥–µ–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã—Ö tokenizer –∏ model
        input_embedding = encode_description(user_input, tokenizer, model)

        # –ü–æ–∏—Å–∫ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Faiss
        _, sorted_indices = index.search(input_embedding.reshape(1, -1), 5)

        # –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—Ç—Ä–æ–∫ –∏–∑ DataFrame
        recs = df.iloc[sorted_indices[0]].reset_index(drop=True)
        recs.index = recs.index + 1

        if user_select_genre: 
            genres_selected = pd.Series(user_select_genre)
            genre_mask = df['genre'].str.contains('')
            for i in range(len(genres_selected)):
                genre_mask_i = df['genre'].str.contains(genres_selected.iloc[i])
                genre_mask = genre_mask & genre_mask_i
            recs = recs[genre_mask]

        if not recs.empty:
            # –í—ã–≤–æ–¥ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∏–ª—å–º–æ–≤ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
            st.subheader("–†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∏–ª—å–º—ã üéâ:")
            for i in range(min(5, len(recs))):
                st.markdown(f"<span style='font-size:{20}px; color:purple'>{recs['movie_title'].iloc[i]}</span>", unsafe_allow_html=True)
                # –°–æ–∑–¥–∞–µ–º –¥–≤–µ –∫–æ–ª–æ–Ω–∫–∏: –æ–¥–Ω—É –¥–ª—è —Ç–µ–∫—Å—Ç–∞, –¥—Ä—É–≥—É—é –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                col1, col2 = st.columns([2, 1])

                # –í  –∫–æ–ª–æ–Ω–∫–µ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Ñ–∏–ª—å–º–∞, –æ–ø–∏—Å–∞–Ω–∏–µ, —Ä–æ–ª–∏ –∏ —Å—Å—ã–ª–∫—É
                col1.info(recs['description'].iloc[i])
                col1.markdown(f"**–í —Ä–æ–ª—è—Ö:** {recs['actors'].iloc[i]}")
                col1.markdown(f"**–§–∏–ª—å–º –º–æ–∂–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å [–∑–¥–µ—Å—å]({recs['page_url'].iloc[i]})**")

                # –í  –∫–æ–ª–æ–Ω–∫–µ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                col2.image(recs['image_url'].iloc[i], caption=recs['movie_title'].iloc[i], width=200)
            
            with st.sidebar:
                st.info("""
                    #### –ú—ã —Å–º–æ–≥–ª–∏ –ø–æ–º–æ—á—å –≤–∞–º —Å –≤—ã–±–æ—Ä–æ–º? 
                """)
                feedback = st.text_input('–ü–æ–¥–µ–ª–∏—Ç–µ—Å—å —Å –Ω–∞–º–∏ –≤–∞—à–∏–º –º–Ω–µ–Ω–∏–µ–º')
            
                feedback_button = st.button("–û—Ç–ø—Ä–∞–≤–∏—Ç—å –æ—Ç–∑—ã–≤", key="feedback_button")
            
            if feedback_button and feedback:
                st.success("–°–ø–∞—Å–∏–±–æ, –∫–∞–∂–¥—ã–π –¥–µ–Ω—å –º—ã —Å—Ç–∞—Ä–∞–µ–º—Å—è –±—ã—Ç—å –ª—É—á—à–µ –¥–ª—è –≤–∞—Å üíü")
            elif feedback_button:
                st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –æ—Ç–∑—ã–≤ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π.")
        else:
            st.subheader("–ü–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ñ–∏–ª—å–º–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –æ—Å–ª–∞–±—å—Ç–µ —Ñ–∏–ª—å—Ç—Ä—ã üòî:")
